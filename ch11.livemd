<!-- livebook:{"persist_outputs":true} -->

# Chapter 11. Model Everything with Transformers

```elixir
Mix.install(
  [
    {:bumblebee, "~> 0.5"},
    {:axon, "~> 0.6"},
    {:nx, "~> 0.7"},
    {:kino, "~> 0.8"},
    {:kino_bumblebee, ">= 0.0.0"},
    {:exla, ">= 0.0.0"}
  ],
  config: [nx: [default_backend: {EXLA.Backend, client: :cuda}]]
)

# export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}
# export XLA_TARGET=cuda120 
# Nx.global_default_backend(EXLA.Backend)
Nx.Defn.global_default_options(compiler: EXLA)
```

## Introduction

Transformers have proven extremely generalizable on a wide-range of input modalities.

Transformers are a class of deep learning models that were originally designed
for natural language processing. they work well in audio processing, computer vision, and more.

There is seemingly no limit to the power of a carefully crafted
transformer model and a lot of input data.

Transformers aren’t necessarily the best model for modeling everything, but
they do quite well at modeling a lot of things.

**Bumblebee** is an Elixir library which consists of pre-trained Axon models as well as out-of-the-box pipelines for solving machine learning problems.

## Paying Attention

The key feature of transformers is in how the apply attention.

Sequence-to-sequence models are designed specifically for problems in which
the objective is to map a source sequence to a target sequence.

Sequence-to-
sequence models consist of an encoder which is responsible for summarizing
the information present in the source sequence in a context vector and a
decoder which is initialized with the context vector and produces the target
sequence.

First, the encoder extracts meaning from the source
sequence, then the decoder uses this meaning to generate a target sequence.

In RNN, long sequences, it’s common for latter portions of the sequence to be overrepresented in the final state, while earlier portions are forgotten.

To overcome the problem of forgetting, you can introduce a shortcut that
computes the alignment between source and target sentences. This is the
attention mechanism.

Attention provides a map that indicates how much each hidden state should be weighed into each output token.

The attention matrix essentially tells you how important each word
in the source sequence is to the target sequence.

Attention enables a model to learn to selectively pay
attention to certain tokens in the input.

## Going from RNNs to Transformers

Attention provides a shortcut between source and target sequences. This
helps a recurrent model learn longer sequences by highlighting which portions
of the context vector map to portions of the target sequence.

The recurrent process of a RNN works on a single time step in the forward or reverse
direction, so it’s difficult to capture relationships between non-adjacent tokens.

Self-attention highlights relationships between words in a sequence.

The typical transformer architecture makes use of an encoder-decoder architecture on a masked language modeling task.

The encoder in a transformer typically consists of a collection of multiple
encoder layers and operates on a representation of the source sequence. Each
encoder layer is identical, and consists of some form of self-attention and
some series of output projections. The actual variant of self-attention in use
in a transformer is typically multi-head self-attention. Multi-head self-attention
is identical to self-attention with one slight exception.

In single-headed self-attention, the model computes one attention matrix,
which means it learns to weight the relationships between tokens in one way.
In multi-headed self-attention, the model computes multiple (typically 12)
different attention matrices (heads).

The decoder in a transformer model typically consists of a collection of multiple
decoder layers and operates on a representation of the target
sequence—usually the source sequence shifted to the right by one token—and
some information about the source sequence from the encoder. Each decoder
layer also consists of some variant of self-attention, but the decoder also
makes use of cross-attention. The decoder layer computes multi-headed self-
attention on the target sequence. The decoder layer also computes multi-
headed cross-attention between information provided by the encoder and the
target sequence.

One issue with using just attention to model temporal data is that transformers have no way of representing temporal dependencies. Most transformers introduce a positional embedding or positional encoding which injects information about positional relationships into the
model.

Most models are differentiated only by
slight tweaks in specific parts such as the attention implementation, the
positional encoding used, or the training process.

Transformers prove significantly more powerful than their recurrent counterparts. Additionally, transformers are readily parallelizable and are significantly more scalable
than an equivalent recurrent neural network.

## Using Transformers with Bumblebee

**Zero-shot Classification with BART**

Zero-shot text classification is a task in natural language processing where a model is trained on a set of labeled examples but is then able to classify new examples from previously unseen classes.

```elixir
# the Bumblebee module to load a pre-trained model and tokenizer 
# directly from the HuggingFace hub.

# Bumblebee is designed to support multiple model hubs.

# bart-large-mnli is an instantiation of the BART transformer
# architure from Facebook.
{:ok, model} = Bumblebee.load_model({:hf, "facebook/bart-large-mnli"})
{:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, "facebook/bart-large-mnli"})
# The MNLI variant is trained on natural language inference tasks, 
# which attempt to predict the probability a given hypothesis is true based
# on some input text.


# It’s important that you use a model’s corresponding pre-trained
# tokenizer because it will encode text in the same manner the model 
# was exposed to during training.

```

<!-- livebook:{"output":true} -->

```

22:18:48.922 [info] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355

22:18:48.924 [info] XLA service 0x7fd9943cad00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:

22:18:48.924 [info]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5

22:18:48.924 [info] Using BFC allocator.

22:18:48.924 [info] XLA backend allocating 5420482560 bytes on device 0 for BFCAllocator.

22:18:48.928 [info] failed to allocate 5.05GiB (5420482560 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory

22:18:50.680 [info] Loaded cuDNN version 8907

22:18:50.748 [info] Using nvlink for parallel linking

```

<!-- livebook:{"output":true} -->

```
{:ok,
 %Bumblebee.Text.PreTrainedTokenizer{
   native_tokenizer: #Tokenizers.Tokenizer<[
     vocab_size: 50265,
     byte_fallback: false,
     continuing_subword_prefix: "",
     dropout: nil,
     end_of_word_suffix: "",
     fuse_unk: false,
     model_type: "bpe",
     unk_token: nil
   ]>,
   type: :bart,
   special_tokens: %{
     mask: "<mask>",
     pad: "<pad>",
     bos: "<s>",
     cls: "<s>",
     eos: "</s>",
     sep: "</s>",
     unk: "<unk>"
   },
   additional_special_tokens: [],
   add_special_tokens: true,
   length: nil,
   pad_direction: :right,
   truncate_direction: :right,
   return_attention_mask: true,
   return_token_type_ids: true,
   return_special_tokens_mask: false,
   return_offsets: false,
   return_length: false
 }}
```

```elixir
model.params
```

<!-- livebook:{"output":true} -->

```
%{
  "decoder.blocks.7.self_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35493>
      [-0.003448486328125, 1.3649463653564453e-4, 0.01486968994140625, 7.51495361328125e-4, -0.0027313232421875, 0.002681732177734375, -0.0074310302734375, 0.0012960433959960938, -0.006732940673828125, -0.004520416259765625, -0.005741119384765625, 7.004737854003906e-4, -0.01030731201171875, -0.014984130859375, -0.02484130859375, -0.006862640380859375, 0.002490997314453125, -0.0055999755859375, 0.0071563720703125, -0.0024967193603515625, 0.0012273788452148438, 0.0107574462890625, 3.139972686767578e-4, 0.01000213623046875, -0.0017461776733398438, -0.0156097412109375, -0.00896453857421875, 0.00949859619140625, 0.0129547119140625, -0.00499725341796875, -0.00588226318359375, 0.007610321044921875, -0.01508331298828125, 0.00313568115234375, 9.57489013671875e-4, -0.01079559326171875, 0.003307342529296875, -0.00948333740234375, 0.0038127899169921875, -0.01556396484375, 0.00351715087890625, -0.004543304443359375, -0.004383087158203125, -9.984970092773438e-4, 0.01535797119140625, -0.00307464599609375, 0.0018949508666992188, -3.535747528076172e-4, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35490>
      [
        [0.03692626953125, -0.052337646484375, 0.06658935546875, -0.001728057861328125, 0.013031005859375, 0.052001953125, -0.0182952880859375, -0.001567840576171875, -0.0268096923828125, -0.05279541015625, -0.030792236328125, -0.0836181640625, 0.01561737060546875, 0.0287933349609375, -0.0062713623046875, 0.0379638671875, 0.0099029541015625, -0.0187530517578125, 0.064453125, -0.072998046875, -0.0557861328125, 0.0208587646484375, 0.016510009765625, -0.031219482421875, -0.046234130859375, -0.0047760009765625, 0.025848388671875, 0.00860595703125, 0.0025348663330078125, -0.031982421875, 0.0167694091796875, -0.0335693359375, 0.0172119140625, 0.0259246826171875, 0.02337646484375, 0.020233154296875, 0.024261474609375, -0.01318359375, -0.038330078125, -0.0086822509765625, -0.005340576171875, 0.021697998046875, -0.06243896484375, -0.06231689453125, -0.04498291015625, 0.016754150390625, 0.003692626953125, ...],
        ...
      ]
    >
  },
  "encoder.blocks.7.self_attention.key" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35811>
      [7.194280624389648e-5, 3.2901763916015625e-4, 0.0019893646240234375, -1.9633769989013672e-4, -1.493692398071289e-4, -0.0012359619140625, 5.549192428588867e-5, 0.003173828125, 6.632804870605469e-4, -0.0018672943115234375, 3.540515899658203e-4, 0.01071929931640625, 7.987022399902344e-5, 2.7441978454589844e-4, 4.988908767700195e-5, 0.001373291015625, -0.001125335693359375, 0.0014982223510742188, -0.001155853271484375, 8.0108642578125e-5, 8.950233459472656e-4, 8.249282836914062e-4, 0.0022792816162109375, -0.0022068023681640625, 3.628730773925781e-4, -4.563331604003906e-4, 0.0013141632080078125, -0.0012903213500976562, -0.0012187957763671875, 5.662441253662109e-6, -1.729726791381836e-4, 7.810592651367188e-4, -8.296966552734375e-4, 1.1914968490600586e-4, 0.012847900390625, -4.906654357910156e-4, -6.270408630371094e-4, 0.0032863616943359375, 2.6488304138183594e-4, -1.6427040100097656e-4, -0.001163482666015625, 0.0016384124755859375, -8.335113525390625e-4, 9.102821350097656e-4, 0.0012416839599609375, -0.001506805419921875, -0.0017633438110351562, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35808>
      [
        [0.08538818359375, 0.0303955078125, -0.123046875, 0.0216064453125, 0.05035400390625, 0.040283203125, -0.0293426513671875, 0.0291900634765625, 0.1485595703125, -0.0026798248291015625, 0.07275390625, 0.09844970703125, 0.01395416259765625, -0.12408447265625, -0.101318359375, 0.18408203125, 0.051971435546875, 0.0029697418212890625, -0.07281494140625, 0.11767578125, 0.05078125, 0.1629638671875, 0.03936767578125, 0.0787353515625, -0.2431640625, -0.005680084228515625, 0.00940704345703125, 0.0596923828125, 0.036346435546875, 0.07623291015625, -0.069091796875, 0.10443115234375, -0.0167388916015625, 0.1204833984375, 0.052215576171875, -0.0308074951171875, -0.038818359375, 0.01422119140625, -0.093017578125, 0.1041259765625, 0.10882568359375, 0.08209228515625, 0.028717041015625, 0.06829833984375, 0.134765625, 0.10406494140625, ...],
        ...
      ]
    >
  },
  "decoder.blocks.0.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34665>
      [-0.1512451171875, 0.07666015625, 0.0247650146484375, 0.049774169921875, -0.00743865966796875, 0.006229400634765625, -0.0513916015625, -0.055511474609375, -0.144287109375, -0.0084686279296875, 0.08599853515625, -0.01396942138671875, 0.01157379150390625, -0.09027099609375, 0.0626220703125, -0.037322998046875, 0.180419921875, 0.04150390625, -0.001926422119140625, 0.054656982421875, 0.07830810546875, 0.055816650390625, -0.04632568359375, 0.06329345703125, 0.046051025390625, -0.07659912109375, -0.058258056640625, 0.18212890625, 0.06890869140625, -0.07672119140625, 0.037322998046875, 0.116943359375, -0.1300048828125, 0.1593017578125, 0.1357421875, -0.038299560546875, 0.297607421875, -0.037017822265625, 0.11968994140625, 0.019287109375, 0.1363525390625, 7.683038711547852e-5, -0.05078125, -0.042205810546875, 0.061279296875, -0.038909912109375, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[4096][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34662>
      [
        [0.0227203369140625, 0.1510009765625, 0.0015401840209960938, 0.0166473388671875, 0.0189361572265625, 0.00130462646484375, -0.048126220703125, 0.0650634765625, 0.0164642333984375, 0.1427001953125, 0.0225372314453125, 0.01502227783203125, -0.03033447265625, -0.00594329833984375, -0.007434844970703125, -0.00948333740234375, 0.0105133056640625, -0.023223876953125, -0.07672119140625, 0.004955291748046875, 0.00817108154296875, -0.0285797119140625, 0.004638671875, 0.0019817352294921875, -0.04925537109375, 0.028778076171875, 0.0751953125, 0.0828857421875, -0.044677734375, -0.0504150390625, 0.0109100341796875, 0.057159423828125, 0.0162353515625, 0.0159912109375, -0.044219970703125, 0.0081634521484375, 0.11016845703125, 0.05560302734375, 0.04254150390625, -0.0692138671875, -0.01190948486328125, -0.01302337646484375, 0.0308685302734375, 0.053009033203125, -0.0015344619750976562, ...],
        ...
      ]
    >
  },
  "encoder.blocks.0.self_attention_norm" => %{
    "beta" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36443>
      [0.005954742431640625, 0.09112548828125, 0.10577392578125, 0.011627197265625, -0.0127410888671875, -0.0887451171875, 0.010833740234375, 0.02899169921875, -0.14404296875, 0.1402587890625, 0.295166015625, -0.0191650390625, 0.026214599609375, 0.1890869140625, -0.07501220703125, -0.06634521484375, 0.1905517578125, -0.12359619140625, 0.150146484375, -0.1168212890625, 0.390625, 0.067138671875, 0.1710205078125, -0.046630859375, -0.08819580078125, -0.05242919921875, -0.6298828125, 0.0987548828125, -0.347900390625, -0.10302734375, 0.1181640625, 0.03363037109375, 0.166748046875, 0.03594970703125, 0.0023365020751953125, 0.0867919921875, 0.1522216796875, 0.151611328125, -0.1005859375, -0.01273345947265625, 0.4384765625, 0.04388427734375, -0.384033203125, -0.07965087890625, 0.01323699951171875, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36440>
      [0.53466796875, 0.5390625, 0.54345703125, 0.420166015625, 0.385498046875, 0.472412109375, 0.5146484375, 0.509765625, 0.60009765625, 0.53759765625, 0.63623046875, 0.49560546875, 0.44384765625, 0.521484375, 0.580078125, 0.460693359375, 0.489501953125, 0.44580078125, 0.5302734375, 0.5556640625, 0.46240234375, 0.4716796875, 0.5556640625, 0.47607421875, 0.483642578125, 0.442138671875, 0.564453125, 0.546875, 0.5205078125, 0.47119140625, 0.58935546875, 0.556640625, 0.587890625, 0.469970703125, 0.50341796875, 0.54443359375, 0.71435546875, 0.61328125, 0.57275390625, 0.4267578125, 0.5263671875, 0.56884765625, 0.57421875, 0.4453125, ...]
    >
  },
  "decoder.blocks.2.self_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36105>
      [0.01256561279296875, -0.0186004638671875, 0.01163482666015625, -0.0085906982421875, -0.013763427734375, 0.01641845703125, -0.01438140869140625, 0.039093017578125, -0.0180816650390625, 0.050262451171875, 0.0230712890625, -0.009918212890625, 0.0948486328125, 0.0182647705078125, 0.006824493408203125, -0.032623291015625, 0.044830322265625, -0.014404296875, -0.0092620849609375, 0.041778564453125, 0.0235595703125, 0.039642333984375, -0.00794219970703125, 0.0743408203125, -0.0552978515625, 1.8417835235595703e-4, 0.0020809173583984375, 0.0849609375, 0.022552490234375, -0.0280303955078125, 0.0094146728515625, -7.023811340332031e-4, -0.041778564453125, 0.047821044921875, -0.0163421630859375, -0.0138092041015625, 0.0850830078125, 0.05767822265625, 0.0162506103515625, 0.0227508544921875, 0.005535125732421875, 0.03387451171875, 0.038818359375, 0.01922607421875, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36102>
      [
        [0.04290771484375, -0.0288848876953125, -0.058380126953125, -0.00556182861328125, -0.10919189453125, 0.044830322265625, 0.044647216796875, 0.060699462890625, -0.0540771484375, 0.0067291259765625, 0.0567626953125, 0.06005859375, -0.00983428955078125, -0.01580810546875, -0.0496826171875, 0.0162506103515625, 0.00830841064453125, 0.07574462890625, -0.0232086181640625, -0.031707763671875, 0.038818359375, 0.044464111328125, 0.01197052001953125, 0.0190887451171875, -0.00769805908203125, 0.06207275390625, -0.045623779296875, 0.00975799560546875, 0.066162109375, -0.003643035888671875, -0.049774169921875, 0.0804443359375, 0.036895751953125, -0.0297698974609375, -0.050079345703125, -0.0751953125, 0.03399658203125, 0.03399658203125, 0.0158233642578125, -0.02606201171875, -0.007419586181640625, 0.06976318359375, 0.06463623046875, ...],
        ...
      ]
    >
  },
  "decoder.blocks.6.output_norm" => %{
    "beta" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36295>
      [0.01519012451171875, -0.0040740966796875, 0.0243072509765625, 0.0202789306640625, 0.0147247314453125, 0.0059814453125, 0.0119781494140625, 0.005558013916015625, 0.01326751708984375, 0.006107330322265625, 0.00954437255859375, 0.0223388671875, -0.062225341796875, 0.01352691650390625, 0.00759124755859375, 0.0093841552734375, -7.5531005859375e-4, 0.0155181884765625, 0.0128936767578125, 0.00510406494140625, 0.0202178955078125, 0.0111846923828125, 0.01039886474609375, 0.01280975341796875, 0.0072784423828125, 0.00713348388671875, 0.0126190185546875, 0.002262115478515625, 0.01079559326171875, 0.00868988037109375, 0.01415252685546875, 0.013916015625, 0.00945281982421875, 0.0068511962890625, 8.282661437988281e-4, 0.0091705322265625, 0.005451202392578125, 0.00713348388671875, 0.0068817138671875, 0.00911712646484375, -0.031951904296875, 0.01393890380859375, 0.0111236572265625, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36292>
      [0.400390625, 0.444091796875, 0.433349609375, 0.408935546875, 0.395751953125, 0.397216796875, 0.41357421875, 0.40966796875, 0.412353515625, 0.405029296875, 0.397705078125, 0.41357421875, 0.4365234375, 0.415283203125, 0.411376953125, 0.416259765625, 0.431396484375, 0.403564453125, 0.398193359375, 0.40771484375, 0.42041015625, 0.415283203125, 0.411376953125, 0.41259765625, 0.4150390625, 0.413818359375, 0.425048828125, 0.407470703125, 0.401123046875, 0.4033203125, 0.410400390625, 0.41162109375, 0.413330078125, 0.40087890625, 0.4013671875, 0.416015625, 0.41455078125, 0.412109375, 0.3974609375, 0.414794921875, 0.448974609375, 0.418701171875, ...]
    >
  },
  "decoder.blocks.11.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36091>
      [9.365081787109375e-4, 0.02069091796875, 0.0020275115966796875, -0.0160675048828125, -0.0382080078125, -0.023468017578125, -0.02294921875, -0.01447296142578125, 0.027252197265625, -0.038299560546875, -0.032135009765625, -0.01934814453125, -0.048858642578125, 0.006710052490234375, 0.012115478515625, -0.0269622802734375, 0.0067596435546875, -0.02056884765625, -0.015838623046875, -0.0254364013671875, 0.07879638671875, 0.020294189453125, 0.032012939453125, 0.036041259765625, -0.043243408203125, 0.0233612060546875, 0.0070037841796875, 0.04718017578125, 0.0460205078125, -0.01226043701171875, -0.0455322265625, 0.0201416015625, -0.005146026611328125, -0.01087188720703125, -0.00736236572265625, -0.00165557861328125, -0.0294036865234375, 0.003978729248046875, 0.0190582275390625, -6.189346313476562e-4, 0.0134429931640625, -0.032196044921875, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[4096][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36088>
      [
        [0.01020050048828125, -9.341239929199219e-4, 0.007415771484375, -0.03143310546875, 0.00853729248046875, -0.0108642578125, -0.01056671142578125, 0.02484130859375, 0.0151824951171875, 0.00402069091796875, -0.01328277587890625, -0.004833221435546875, 0.0033512115478515625, 0.019012451171875, 0.013763427734375, 0.006916046142578125, 0.04339599609375, -0.004566192626953125, 0.0221710205078125, 0.01082611083984375, 0.00408935546875, 0.0190887451171875, -0.040252685546875, 0.018402099609375, -0.02166748046875, -0.0251922607421875, -0.0198974609375, -0.0015993118286132812, -0.040008544921875, 0.0213165283203125, 0.00121307373046875, 0.019805908203125, -0.0169219970703125, 0.01953125, -0.003948211669921875, -0.00539398193359375, -0.0127716064453125, -0.01180267333984375, 0.0281524658203125, 0.0164031982421875, -0.009246826171875, ...],
        ...
      ]
    >
  },
  "decoder.blocks.3.self_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35485>
      [7.905960083007812e-4, -5.784034729003906e-4, -0.0059967041015625, -0.00917816162109375, -0.003940582275390625, 0.0223846435546875, -0.00859832763671875, 0.0146942138671875, 0.002410888671875, 0.003215789794921875, -0.03155517578125, 0.00411224365234375, 0.00530242919921875, -0.0054931640625, -0.0013093948364257812, 0.00263214111328125, -0.002040863037109375, -0.0171966552734375, -0.0059356689453125, -0.017608642578125, 0.0117950439453125, -0.0011434555053710938, 0.0124969482421875, 0.0030231475830078125, -0.005474090576171875, 0.01593017578125, 0.0084381103515625, 0.005542755126953125, -0.005619049072265625, -9.160041809082031e-4, -0.01103973388671875, -0.0090789794921875, 0.002887725830078125, 0.00331878662109375, -0.0021266937255859375, -0.0015096664428710938, 0.01119232177734375, -0.003936767578125, 1.5795230865478516e-4, -0.01483154296875, -0.00673675537109375, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35482>
      [
        [0.09356689453125, -0.058563232421875, -0.01216888427734375, -0.0697021484375, -0.05426025390625, 0.0225830078125, 0.08251953125, -0.01324462890625, -0.0162811279296875, 0.0455322265625, -0.06439208984375, 0.03173828125, 0.0211639404296875, 0.006931304931640625, -0.10906982421875, 0.0159149169921875, -0.0072479248046875, -0.0693359375, 0.0031757354736328125, -0.0173187255859375, 0.035400390625, -0.0255126953125, 0.048248291015625, 0.06536865234375, -0.0292816162109375, -0.067138671875, -0.052734375, 0.049957275390625, 0.0256500244140625, 0.01366424560546875, 0.022552490234375, -0.030670166015625, -0.018585205078125, 0.0018777847290039062, -0.00921630859375, -0.06201171875, 0.01116943359375, 0.00434112548828125, 0.031646728515625, 0.0090179443359375, ...],
        ...
      ]
    >
  },
  "decoder.blocks.3.self_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35907>
      [0.0283203125, 0.00441741943359375, 0.01959228515625, 0.03375244140625, 0.01093292236328125, 6.251335144042969e-4, -0.01058197021484375, 0.038360595703125, -0.04693603515625, 0.037322998046875, 0.00791168212890625, 0.031280517578125, 0.01227569580078125, 0.07867431640625, -0.007762908935546875, -0.00818634033203125, 0.0065765380859375, 0.00478363037109375, 0.0149688720703125, 0.044219970703125, -0.038909912109375, 0.038726806640625, 0.0029201507568359375, 0.044525146484375, -0.00970458984375, 0.0121307373046875, -0.013458251953125, 0.0316162109375, 0.0295867919921875, -9.245872497558594e-4, 0.021759033203125, -0.0014638900756835938, 0.0051116943359375, -0.010833740234375, -0.0362548828125, -0.0187530517578125, 0.097412109375, -0.025177001953125, 0.050323486328125, 0.005435943603515625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35904>
      [
        [-0.0089569091796875, -0.0176239013671875, -0.01465606689453125, 0.03564453125, 0.03985595703125, 0.016326904296875, -0.01114654541015625, -0.042388916015625, -0.00914764404296875, -0.08465576171875, 0.0258026123046875, -0.0200042724609375, 0.038299560546875, -0.0171051025390625, 0.04217529296875, 0.006946563720703125, -0.037689208984375, -0.08135986328125, 0.01197052001953125, -0.040435791015625, 0.0017032623291015625, 0.021148681640625, -0.005756378173828125, -0.04217529296875, 0.0073089599609375, -0.0247039794921875, 0.05499267578125, -0.016326904296875, -0.0257568359375, -0.0296173095703125, 0.0258026123046875, -0.0699462890625, -0.056793212890625, 0.041656494140625, 0.06671142578125, -0.06414794921875, 0.099365234375, -0.033203125, -0.0166168212890625, ...],
        ...
      ]
    >
  },
  "encoder.blocks.4.self_attention.key" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35865>
      [-4.9591064453125e-4, 0.001819610595703125, -0.0036602020263671875, -0.0012006759643554688, -0.0045013427734375, 8.406639099121094e-4, 7.724761962890625e-5, 0.0042266845703125, 0.00154876708984375, 0.0010852813720703125, 0.0036144256591796875, -8.535385131835938e-4, -1.2695789337158203e-5, -9.136199951171875e-4, 0.0038967132568359375, -7.004737854003906e-4, 4.851818084716797e-4, -6.594657897949219e-4, 0.0022068023681640625, -6.351470947265625e-4, -1.8775463104248047e-4, 0.00191497802734375, 0.0010890960693359375, -0.0036334991455078125, 0.0052490234375, 0.0011758804321289062, 1.4507770538330078e-4, -8.120536804199219e-4, -3.5071372985839844e-4, 0.0011005401611328125, -0.017059326171875, -5.593299865722656e-4, 0.0028533935546875, 9.603500366210938e-4, -0.0040435791015625, 0.0017490386962890625, 0.002506256103515625, -0.0017404556274414062, -0.002506256103515625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35862>
      [
        [-0.052337646484375, 0.026153564453125, 0.07818603515625, -0.00925445556640625, 0.02215576171875, -0.03570556640625, -0.01473236083984375, -0.1568603515625, 0.0208892822265625, -0.00933837890625, -0.1134033203125, -0.0675048828125, -0.0086669921875, 0.1077880859375, 0.08404541015625, -0.0110626220703125, -0.0298004150390625, -0.061920166015625, -0.09161376953125, -0.0972900390625, -0.049163818359375, 0.059478759765625, 0.017120361328125, 0.05615234375, 0.1571044921875, 0.00738525390625, 0.00907135009765625, -0.00798797607421875, -0.134033203125, -0.005046844482421875, -0.049346923828125, -0.0665283203125, 0.01500701904296875, -0.009124755859375, 0.0751953125, 0.11151123046875, -0.033935546875, -0.031402587890625, ...],
        ...
      ]
    >
  },
  "decoder.blocks.7.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35675>
      [-0.00942230224609375, 0.07525634765625, -0.0276641845703125, -0.10162353515625, 0.1466064453125, -0.0283355712890625, -0.0097808837890625, 0.00737762451171875, -0.017791748046875, 0.0203704833984375, -0.0289764404296875, 0.0213623046875, 0.12841796875, 0.09869384765625, -0.00514984130859375, 0.026031494140625, 0.1064453125, 0.0233917236328125, -0.13623046875, -0.0310516357421875, 0.196044921875, 0.066650390625, -0.08624267578125, 0.0682373046875, 0.07208251953125, -0.00899505615234375, -0.0755615234375, 0.0732421875, -0.07177734375, 0.08221435546875, -0.0198516845703125, 0.09637451171875, -0.25341796875, 0.0312042236328125, -0.13916015625, -0.1041259765625, 0.0537109375, -0.09033203125, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[4096][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35672>
      [
        [-0.0161590576171875, -0.035919189453125, -0.0225982666015625, 0.054595947265625, 0.022125244140625, 0.031158447265625, 0.004261016845703125, 0.001983642578125, 0.004680633544921875, -0.0167388916015625, -0.020660400390625, 1.3113021850585938e-6, -0.0035610198974609375, -0.0156707763671875, -0.01953125, 0.046966552734375, 0.0011167526245117188, 0.0156402587890625, -0.0160064697265625, -0.01065826416015625, 0.00902557373046875, -0.01279449462890625, 0.00274658203125, -0.0099029541015625, -0.007434844970703125, -0.021575927734375, -0.006443023681640625, 0.00708770751953125, 0.0011196136474609375, 0.0260162353515625, -0.01239776611328125, -0.0186920166015625, 0.01071929931640625, -0.00806427001953125, -0.045135498046875, 0.019317626953125, -0.01155853271484375, ...],
        ...
      ]
    >
  },
  "decoder_embedder.position_embedding" => %{
    "kernel" => #Nx.Tensor<
      f32[1026][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36233>
      [
        [-0.003429412841796875, -0.005710601806640625, 8.974075317382812e-4, -7.443428039550781e-4, -0.0010805130004882812, -0.01248931884765625, 0.00437164306640625, 0.00522613525390625, 0.0047454833984375, 0.0027828216552734375, -1.3113021850585938e-4, 0.00759124755859375, -0.00798797607421875, 0.0094146728515625, 0.007099151611328125, -0.004833221435546875, 0.003620147705078125, -0.0047454833984375, 0.01096343994140625, -0.00305938720703125, 0.003330230712890625, -0.00890350341796875, -0.002414703369140625, -7.696151733398438e-4, 2.4318695068359375e-4, -0.017608642578125, -0.001651763916015625, -0.0010471343994140625, -0.0088043212890625, 0.004673004150390625, -0.006381988525390625, 0.01522064208984375, -6.718635559082031e-4, -0.0038089752197265625, 0.0049896240234375, -7.548332214355469e-4, -0.006710052490234375, ...],
        ...
      ]
    >
  },
  "encoder.blocks.4.self_attention.query" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35753>
      [-0.25390625, 0.2626953125, -0.1888427734375, -0.3740234375, -0.44189453125, 0.295166015625, -0.03472900390625, 0.4296875, 0.31103515625, 0.1419677734375, 0.33203125, 0.1639404296875, -0.291748046875, 0.1678466796875, 0.68310546875, 0.176513671875, 0.4814453125, 0.284423828125, 0.42236328125, 0.2191162109375, -0.1854248046875, 0.284912109375, 0.295654296875, 0.00731658935546875, 0.83251953125, 0.2110595703125, -0.52099609375, -0.431396484375, -0.3798828125, 0.53466796875, -0.83154296875, -0.2275390625, 0.203125, 0.6025390625, -0.34130859375, 0.41552734375, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35750>
      [
        [-0.08026123046875, -0.124267578125, 0.084716796875, -0.07232666015625, 0.0628662109375, -0.0986328125, -0.1307373046875, 0.08172607421875, 0.015716552734375, -0.22021484375, 0.0174560546875, -0.022308349609375, 0.07110595703125, -0.0182952880859375, -0.02783203125, 0.0105743408203125, 0.050445556640625, -0.01605224609375, 0.083984375, 0.067138671875, 0.11041259765625, -0.061920166015625, -0.0271759033203125, 0.08966064453125, -0.058502197265625, 0.10003662109375, 0.03582763671875, -0.08441162109375, 0.0110015869140625, 0.0012464523315429688, -0.060943603515625, -0.04827880859375, 0.047607421875, -0.1763916015625, 0.033203125, ...],
        ...
      ]
    >
  },
  "decoder.blocks.2.self_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34993>
      [0.01282501220703125, 0.018096923828125, 0.01137542724609375, -0.005157470703125, -0.00997161865234375, -9.942054748535156e-5, 0.005462646484375, 0.01340484619140625, 8.769035339355469e-4, 0.0079803466796875, 0.003940582275390625, -0.014801025390625, 1.996755599975586e-4, 3.0875205993652344e-4, 0.01038360595703125, -0.00708770751953125, 0.03179931640625, -6.003379821777344e-4, 0.005779266357421875, 0.00409698486328125, 0.006923675537109375, 0.0184783935546875, 9.012222290039062e-4, -0.010955810546875, -0.0289459228515625, 0.007411956787109375, -0.0047454833984375, 0.0148162841796875, -0.00458526611328125, 0.004589080810546875, -8.696317672729492e-5, -0.0200347900390625, 0.01094818115234375, -0.0032367706298828125, -0.04095458984375, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34990>
      [
        [-0.025299072265625, 0.055419921875, 0.064453125, 0.031646728515625, 0.0291290283203125, 0.001674652099609375, 0.06121826171875, 0.007236480712890625, -0.0026798248291015625, -0.00872802734375, 0.0626220703125, 0.04583740234375, -0.058837890625, 0.1619873046875, 0.05596923828125, -0.0426025390625, -0.024261474609375, 0.0013599395751953125, -0.040985107421875, -0.055023193359375, 0.01093292236328125, 0.026702880859375, -0.0215606689453125, 0.00417327880859375, 0.042938232421875, 0.0023593902587890625, -0.04833984375, -0.063720703125, 0.007183074951171875, -0.046966552734375, -0.004894256591796875, -0.0241241455078125, -0.002445220947265625, -0.0679931640625, ...],
        ...
      ]
    >
  },
  "decoder.blocks.7.cross_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35297>
      [0.04443359375, -0.03271484375, 0.0460205078125, 0.00937652587890625, -0.02294921875, -0.049346923828125, 0.0035953521728515625, -0.0059356689453125, 0.01433563232421875, 0.0102081298828125, 0.047760009765625, 0.03253173828125, -0.02960205078125, -0.012115478515625, 0.01538848876953125, 0.044342041015625, -0.08453369140625, 0.06524658203125, 0.0021533966064453125, -0.053558349609375, -0.033416748046875, 0.0076904296875, -0.0521240234375, -0.0413818359375, -0.00408172607421875, 0.0089569091796875, -0.016021728515625, 0.0026149749755859375, -0.07177734375, -0.00879669189453125, 6.060600280761719e-4, 0.0246429443359375, -0.027587890625, -0.03912353515625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35294>
      [
        [0.046600341796875, 0.00429534912109375, 0.0274810791015625, -7.390975952148438e-4, 0.0139007568359375, 0.02374267578125, -0.0499267578125, 0.01300811767578125, -1.417398452758789e-4, -0.0195465087890625, -0.029052734375, 0.051055908203125, 0.01971435546875, 0.043548583984375, -0.00884246826171875, -0.044036865234375, -0.00875091552734375, -0.02264404296875, -0.04541015625, 0.142333984375, 0.01157379150390625, -0.0084075927734375, -0.0084075927734375, -0.06951904296875, -0.068359375, -0.0200347900390625, -0.06683349609375, -0.03192138671875, -0.1279296875, -0.13134765625, -0.0017366409301757812, -0.07147216796875, -0.0127410888671875, ...],
        ...
      ]
    >
  },
  "decoder.blocks.11.cross_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35509>
      [-0.0226287841796875, 9.274482727050781e-4, 0.0024356842041015625, 0.0213623046875, 0.00882720947265625, 0.07958984375, 0.013519287109375, 0.0038967132568359375, -0.010650634765625, -9.212493896484375e-4, -0.01082611083984375, 0.018035888671875, -5.8650970458984375e-5, -0.15283203125, -0.00698089599609375, 3.6835670471191406e-4, -0.005794525146484375, 0.0220184326171875, 0.01247406005859375, 0.0092010498046875, 0.1278076171875, 0.005443572998046875, 9.188652038574219e-4, 0.0147705078125, -0.061859130859375, -0.01373291015625, 0.002532958984375, 0.1494140625, -0.0019235610961914062, 0.009063720703125, 0.01152801513671875, 0.01776123046875, 0.028564453125, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35506>
      [
        [-0.036712646484375, 0.0313720703125, -0.006282806396484375, 0.022003173828125, -0.09814453125, -0.0126953125, 0.140380859375, -0.016326904296875, 0.00850677490234375, -0.00353240966796875, 0.07073974609375, 0.1187744140625, -0.10565185546875, 0.00501251220703125, 0.0540771484375, 0.0031719207763671875, -0.04290771484375, -0.0616455078125, -0.1163330078125, -0.006198883056640625, -0.0916748046875, 0.00836181640625, -0.051300048828125, -0.07379150390625, -0.04827880859375, -0.0849609375, 0.01320648193359375, 0.0423583984375, -0.03472900390625, -0.0693359375, 0.06878662109375, 0.035736083984375, ...],
        ...
      ]
    >
  },
  "encoder.blocks.1.self_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34785>
      [-6.9427490234375e-4, -0.01374053955078125, 0.048919677734375, -0.005458831787109375, -0.1812744140625, -0.0308685302734375, 0.0203094482421875, -0.0261688232421875, 0.0083160400390625, 0.01171112060546875, -0.048370361328125, -0.01409912109375, -0.00878143310546875, -0.0301513671875, 0.0168914794921875, -0.00527191162109375, -0.025970458984375, -0.032257080078125, -0.0141143798828125, 0.01450347900390625, -0.11688232421875, 0.0039520263671875, -0.006526947021484375, -0.009307861328125, 0.047088623046875, 0.044189453125, 0.021270751953125, -0.01470184326171875, 0.0272674560546875, 0.0184783935546875, -0.01032257080078125, 0.04608154296875, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34782>
      [
        [0.035675048828125, 0.01049041748046875, -0.0212249755859375, -0.08953857421875, 0.059600830078125, 0.0015869140625, 0.022705078125, 0.01258087158203125, 6.7901611328125e-4, 0.09576416015625, -0.0270843505859375, -0.041351318359375, 0.007495880126953125, 0.06927490234375, 0.056640625, 0.01085662841796875, 0.0010013580322265625, -0.037384033203125, 0.0110015869140625, 0.054046630859375, 0.07196044921875, -0.0423583984375, 0.0223388671875, -0.01422882080078125, -0.00609588623046875, 0.022125244140625, 0.032989501953125, 0.0183258056640625, 0.01422119140625, -0.0654296875, 0.034637451171875, ...],
        ...
      ]
    >
  },
  "decoder.blocks.2.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34897>
      [-0.061981201171875, 0.01050567626953125, 0.0285797119140625, 0.0303955078125, -0.039031982421875, -0.07696533203125, -0.0264739990234375, 0.10223388671875, -0.01702880859375, -0.055694580078125, 0.1380615234375, 0.00873565673828125, -0.029449462890625, 0.0232086181640625, 0.022308349609375, 0.0167999267578125, 0.093017578125, -0.0186309814453125, 0.0254364013671875, 0.04290771484375, 0.065673828125, 0.0172576904296875, -0.01256561279296875, 0.0972900390625, -0.00759124755859375, -0.0242767333984375, -0.053924560546875, 0.07781982421875, -0.0203857421875, -0.0025424957275390625, -0.029693603515625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[4096][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34894>
      [
        [0.01422882080078125, 0.0888671875, -0.0377197265625, -0.0158843994140625, -0.0302734375, 0.06475830078125, -0.00566864013671875, -0.11602783203125, 0.0465087890625, 0.0389404296875, -0.0134735107421875, 0.03961181640625, -0.0335693359375, 0.003459930419921875, -0.025054931640625, -0.0253753662109375, -0.0178680419921875, 0.0281982421875, 0.0121002197265625, -0.01410675048828125, -0.013580322265625, -0.03515625, -0.025482177734375, 0.005847930908203125, 0.0723876953125, 0.0112457275390625, 0.04949951171875, -7.214546203613281e-4, -0.07659912109375, -0.12396240234375, ...],
        ...
      ]
    >
  },
  "encoder.blocks.8.output_norm" => %{
    "beta" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36097>
      [-0.007266998291015625, 0.07843017578125, 0.049285888671875, -0.0044403076171875, -0.036590576171875, -0.004489898681640625, -0.025146484375, 0.01377105712890625, 0.021575927734375, -0.0199127197265625, -0.061492919921875, -0.0145111083984375, -0.019927978515625, 0.0091705322265625, -0.0318603515625, 0.009674072265625, -0.00563812255859375, -2.3984909057617188e-4, -0.01099395751953125, -0.04022216796875, -0.007015228271484375, -0.0132904052734375, -0.1722412109375, -0.0011577606201171875, -0.0070648193359375, -0.03082275390625, -0.0018444061279296875, -0.0153350830078125, -0.0087432861328125, -0.0037860870361328125, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36094>
      [0.34912109375, 0.3720703125, 0.370361328125, 0.294677734375, 0.282470703125, 0.316162109375, 0.329833984375, 0.32568359375, 0.366455078125, 0.353759765625, 0.3935546875, 0.309326171875, 0.2919921875, 0.33251953125, 0.35986328125, 0.3095703125, 0.294189453125, 0.28955078125, 0.3076171875, 0.360595703125, 0.266845703125, 0.3056640625, 0.370361328125, 0.322509765625, 0.2939453125, 0.288818359375, 0.359375, 0.344970703125, 0.28662109375, ...]
    >
  },
  "decoder.blocks.3.self_attention.key" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34867>
      [-0.01268768310546875, 3.159046173095703e-4, 0.0232086181640625, -0.0362548828125, -0.01178741455078125, -0.004573822021484375, -0.0016307830810546875, -0.01561737060546875, -0.00514984130859375, -0.07940673828125, -0.0026302337646484375, -0.022705078125, 0.01904296875, 0.03533935546875, -0.02032470703125, 0.07598876953125, 0.02130126953125, -0.005611419677734375, 0.002002716064453125, 0.01041412353515625, 0.004398345947265625, -0.0018129348754882812, -0.021331787109375, 0.005115509033203125, -0.00948333740234375, 0.035430908203125, -0.003139495849609375, 0.01380157470703125, 0.0027256011962890625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34864>
      [
        [0.0203704833984375, 0.0157012939453125, 0.00684356689453125, -0.02166748046875, -0.0272369384765625, -0.00568389892578125, 0.08203125, 0.030792236328125, 0.034515380859375, 0.0016908645629882812, 0.015869140625, 0.018951416015625, -0.048126220703125, 0.05389404296875, -0.021392822265625, -0.0257415771484375, 0.039337158203125, 0.0259246826171875, -0.002838134765625, 0.0018596649169921875, -0.0241851806640625, 0.05206298828125, 0.069091796875, -0.05780029296875, -0.0292205810546875, 0.041748046875, -0.035614013671875, -0.05450439453125, ...],
        ...
      ]
    >
  },
  "encoder.blocks.8.ffn.intermediate" => %{
    "bias" => #Nx.Tensor<
      f32[4096]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35761>
      [-0.1722412109375, 0.035491943359375, -0.1510009765625, -0.034149169921875, -0.05352783203125, -0.158447265625, -0.1046142578125, -0.1934814453125, -0.1573486328125, -0.007007598876953125, -0.2386474609375, -0.043304443359375, -0.121337890625, -0.22021484375, -0.1282958984375, -0.0055084228515625, 0.0147247314453125, 0.0170745849609375, -0.035369873046875, 0.0020122528076171875, -0.12298583984375, -0.143798828125, -0.1929931640625, -0.251953125, -0.035675048828125, -0.2177734375, -0.261962890625, 0.026153564453125, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][4096]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35758>
      [
        [0.00753021240234375, 0.00141143798828125, -0.01413726806640625, -0.022705078125, 0.004039764404296875, -0.0113525390625, 0.07061767578125, -0.0276947021484375, -0.0955810546875, -0.003231048583984375, -0.0450439453125, 0.01332855224609375, -0.06805419921875, -0.08935546875, 0.06829833984375, -0.06329345703125, 0.0151519775390625, 0.0266571044921875, -0.038787841796875, -0.0233612060546875, -0.01255035400390625, 0.00402069091796875, 0.0031528472900390625, -0.0594482421875, -0.00621795654296875, -0.03692626953125, -0.04693603515625, ...],
        ...
      ]
    >
  },
  "decoder_embedder.norm" => %{
    "beta" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35767>
      [-0.039581298828125, -0.302001953125, 0.10107421875, 0.005664825439453125, 0.1236572265625, 0.00383758544921875, 0.0170745849609375, 0.0740966796875, 0.07049560546875, -0.01512908935546875, 0.20751953125, -0.0175933837890625, 0.136474609375, 0.05853271484375, -0.043975830078125, 0.07684326171875, -0.1138916015625, 0.028594970703125, 0.019622802734375, 0.0186004638671875, -0.459228515625, -0.0188446044921875, 0.053314208984375, -0.05218505859375, 0.073486328125, -0.02166748046875, 0.12054443359375, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35764>
      [0.441162109375, 0.057861328125, 0.3369140625, 0.425048828125, 0.444580078125, 0.467041015625, 0.4931640625, 0.458251953125, 0.468017578125, 0.463623046875, 0.38818359375, 0.471435546875, 0.52587890625, 0.478759765625, 0.466796875, 0.45849609375, 0.44921875, 0.46826171875, 0.419921875, 0.46630859375, 0.07379150390625, 0.478515625, 0.472900390625, 0.44775390625, 0.447998046875, 0.473876953125, ...]
    >
  },
  "encoder.blocks.10.self_attention.query" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36303>
      [-0.170654296875, -0.07257080078125, 0.2235107421875, 0.10198974609375, -0.1329345703125, -0.0244140625, 0.53955078125, 0.2188720703125, 0.0279541015625, -0.294921875, 0.027099609375, 0.441162109375, 0.1475830078125, -0.422119140625, -0.055999755859375, 0.45458984375, 0.256103515625, -0.13671875, -0.04803466796875, -0.0841064453125, -0.08966064453125, 0.30908203125, 0.29052734375, -0.190185546875, 0.01428985595703125, 0.44775390625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36300>
      [
        [0.006084442138671875, 0.0819091796875, 0.0906982421875, -0.0743408203125, 0.14990234375, -0.04205322265625, -0.17138671875, 0.04736328125, -0.00958251953125, -0.12176513671875, -0.08172607421875, 0.072021484375, 0.00891876220703125, -0.01140594482421875, -0.01442718505859375, -0.0838623046875, -0.1168212890625, -0.12017822265625, -0.04547119140625, -0.1666259765625, 0.06170654296875, 0.00951385498046875, 0.051666259765625, 0.0821533203125, -0.08868408203125, ...],
        ...
      ]
    >
  },
  "decoder.blocks.8.cross_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35235>
      [0.07403564453125, -0.058685302734375, 0.0225372314453125, 0.0391845703125, -0.0305023193359375, 0.049896240234375, -0.00804901123046875, 0.07781982421875, 0.022674560546875, 0.0030155181884765625, 0.05718994140625, -0.04901123046875, 0.00562286376953125, -0.005748748779296875, 0.0137939453125, 0.062347412109375, -0.0154876708984375, 0.01812744140625, 0.03265380859375, 0.0182342529296875, -0.08984375, -0.0211944580078125, 0.0156707763671875, -0.1265869140625, 0.0304107666015625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35232>
      [
        [0.046539306640625, 0.0137786865234375, 0.04595947265625, -0.0267333984375, 0.0955810546875, -0.01177978515625, 0.018310546875, -0.00914764404296875, -0.031890869140625, -0.0243072509765625, 0.023406982421875, -0.0199127197265625, 0.0227203369140625, 0.00591278076171875, -0.08935546875, 0.0292816162109375, 0.00608062744140625, 0.0196990966796875, 0.0264892578125, -0.0243377685546875, 0.0200958251953125, -0.01520538330078125, 0.0169677734375, 0.11309814453125, ...],
        ...
      ]
    >
  },
  "encoder.blocks.1.output_norm" => %{
    "beta" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34649>
      [-0.00128936767578125, 0.017333984375, -0.0198516845703125, -0.01421356201171875, -0.0302886962890625, -0.005748748779296875, -0.0156707763671875, -0.03558349609375, 0.04095458984375, -0.00730133056640625, 0.01351165771484375, 0.004810333251953125, -0.002674102783203125, -0.041046142578125, -0.0013685226440429688, 0.0110321044921875, -0.0265350341796875, 0.00897979736328125, -0.0295562744140625, 0.0032482147216796875, -0.0032939910888671875, -0.01019287109375, -0.0782470703125, -0.01154327392578125, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34646>
      [0.353271484375, 0.347900390625, 0.3642578125, 0.338623046875, 0.2998046875, 0.344482421875, 0.35791015625, 0.349365234375, 0.365234375, 0.3623046875, 0.40234375, 0.36181640625, 0.3447265625, 0.34716796875, 0.362060546875, 0.350830078125, 0.355712890625, 0.342529296875, 0.355712890625, 0.354736328125, 0.286865234375, 0.3486328125, 0.365478515625, ...]
    >
  },
  "encoder.blocks.1.self_attention_norm" => %{
    "beta" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34605>
      [-0.043487548828125, -0.210693359375, 0.07513427734375, 0.00469207763671875, 0.1595458984375, 0.033843994140625, 0.057037353515625, 0.1029052734375, -0.1812744140625, -0.0294342041015625, 0.35302734375, -0.036865234375, -6.003379821777344e-4, 0.11505126953125, 0.0191192626953125, -0.08575439453125, 0.01340484619140625, -0.0168914794921875, 0.0810546875, 0.039337158203125, -0.09393310546875, 0.0017385482788085938, 0.311279296875, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34602>
      [0.55810546875, 0.5537109375, 0.5732421875, 0.409423828125, 0.432373046875, 0.486328125, 0.5302734375, 0.5302734375, 0.60693359375, 0.56298828125, 0.6630859375, 0.51904296875, 0.44384765625, 0.54833984375, 0.587890625, 0.4853515625, 0.498291015625, 0.4443359375, 0.537109375, 0.56982421875, 0.3486328125, 0.491455078125, ...]
    >
  },
  "decoder.blocks.4.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36465>
      [0.0086517333984375, 0.07562255859375, -0.02484130859375, -0.037841796875, -0.049346923828125, 0.037109375, -0.02001953125, 0.1436767578125, 0.056640625, 0.0017910003662109375, 0.06982421875, 0.061004638671875, 0.05889892578125, -0.0108642578125, -0.00399017333984375, -0.04473876953125, 0.1094970703125, -0.0631103515625, -0.1043701171875, 0.06591796875, 0.1595458984375, -0.0193328857421875, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[4096][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36462>
      [
        [3.330707550048828e-4, 0.0281219482421875, 0.0015544891357421875, -0.007328033447265625, 0.0198822021484375, 0.02569580078125, -0.05389404296875, -0.0028934478759765625, 0.035980224609375, 0.05670166015625, -0.02899169921875, 0.0305328369140625, -0.0023860931396484375, -0.0260162353515625, -1.232624053955078e-4, 0.05084228515625, 0.050445556640625, 0.06585693359375, 0.0204010009765625, -0.027099609375, -0.031951904296875, ...],
        ...
      ]
    >
  },
  "encoder.blocks.1.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36113>
      [0.02508544921875, 0.09698486328125, 0.0012521743774414062, -0.028350830078125, 0.048248291015625, 0.025054931640625, -0.0303497314453125, -0.04595947265625, 0.03125, -0.0242919921875, -0.08660888671875, 0.0250396728515625, -0.06793212890625, -0.0789794921875, -0.0311126708984375, 0.0248870849609375, -0.0406494140625, -0.01439666748046875, -0.017059326171875, 0.0255889892578125, -0.08306884765625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[4096][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36110>
      [
        [0.0252227783203125, -0.053009033203125, 0.022552490234375, -0.053924560546875, -0.08685302734375, 0.11859130859375, 0.09112548828125, 0.038330078125, 0.055816650390625, -0.018585205078125, 0.02081298828125, 0.07086181640625, -0.08795166015625, 0.0634765625, -0.00630950927734375, 0.01605224609375, 0.01207733154296875, 0.0511474609375, 0.03985595703125, -0.033111572265625, ...],
        ...
      ]
    >
  },
  "encoder.blocks.2.self_attention.key" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35281>
      [3.123283386230469e-4, -4.589557647705078e-6, 3.142356872558594e-4, -2.722740173339844e-4, -0.0020847320556640625, 4.2939186096191406e-4, 0.0019168853759765625, 5.612373352050781e-4, -3.745555877685547e-4, -2.989768981933594e-4, 1.3768672943115234e-5, 0.002704620361328125, 0.0015277862548828125, -1.7762184143066406e-5, 1.8835067749023438e-5, -6.6375732421875e-4, -0.00353240966796875, -7.658004760742188e-4, 8.001327514648438e-4, 4.3964385986328125e-4, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35278>
      [
        [0.079345703125, 3.075599670410156e-4, 0.017852783203125, 0.051544189453125, -0.01235198974609375, -0.037567138671875, -0.1751708984375, 0.0015497207641601562, -0.044952392578125, 0.0360107421875, -0.0234375, -8.296966552734375e-4, -0.004730224609375, 0.0197296142578125, -0.05096435546875, 0.09405517578125, 0.05291748046875, -0.005603790283203125, -0.054595947265625, ...],
        ...
      ]
    >
  },
  "encoder.blocks.3.ffn.intermediate" => %{
    "bias" => #Nx.Tensor<
      f32[4096]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35849>
      [-0.153564453125, -0.0947265625, -0.0762939453125, -0.2291259765625, -0.1597900390625, -0.07281494140625, -0.1343994140625, -0.12042236328125, -0.11395263671875, -0.1810302734375, -0.135009765625, -0.145263671875, -0.1488037109375, -0.1279296875, -0.1317138671875, -0.07421875, -0.103271484375, -0.0128173828125, -0.0740966796875, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][4096]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35846>
      [
        [0.051055908203125, -0.0181732177734375, -0.048797607421875, -0.07318115234375, 0.04534912109375, 0.040435791015625, -6.551742553710938e-4, -0.016937255859375, 0.050140380859375, -0.0230255126953125, -0.0016460418701171875, 0.0159912109375, 0.07421875, 0.00800323486328125, -0.00202178955078125, 0.04388427734375, -0.0526123046875, 0.0360107421875, ...],
        ...
      ]
    >
  },
  "decoder.blocks.3.output_norm" => %{
    "beta" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34553>
      [6.303787231445312e-4, -0.0245361328125, 0.021759033203125, 0.0025272369384765625, -0.0018100738525390625, -0.0020122528076171875, -0.002925872802734375, -0.004779815673828125, -0.007541656494140625, -0.005462646484375, -0.005924224853515625, 0.0018053054809570312, -0.034698486328125, 0.0030975341796875, -0.00860595703125, -0.004474639892578125, -0.0120697021484375, -0.0022182464599609375, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34550>
      [0.376953125, 0.361328125, 0.406982421875, 0.38232421875, 0.369873046875, 0.366455078125, 0.3916015625, 0.3828125, 0.375244140625, 0.3759765625, 0.377685546875, 0.394775390625, 0.473876953125, 0.381103515625, 0.380126953125, 0.40283203125, 0.39892578125, ...]
    >
  },
  "sequence_classification_head.dense" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36333>
      [2.104043960571289e-4, -5.245208740234375e-5, -9.72747802734375e-5, 2.9802322387695312e-5, 5.161762237548828e-5, -8.130073547363281e-5, -3.2901763916015625e-5, 9.47713851928711e-6, 3.713369369506836e-5, 1.704692840576172e-5, -2.5200843811035156e-4, -8.922815322875977e-5, -7.718801498413086e-5, -4.6372413635253906e-5, 5.638599395751953e-5, -3.7670135498046875e-5, -9.262561798095703e-5, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36330>
      [
        [-0.0178375244140625, -0.02459716796875, -0.016754150390625, 0.016510009765625, -0.02239990234375, -0.0149993896484375, -0.004974365234375, -0.035369873046875, -0.0011949539184570312, -8.597373962402344e-4, 0.04595947265625, 0.0293121337890625, -0.0079345703125, -0.003612518310546875, -0.028472900390625, 0.032470703125, ...],
        ...
      ]
    >
  },
  "decoder.blocks.9.self_attention.key" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35617>
      [-0.0173797607421875, 0.00983428955078125, 0.00638580322265625, 0.045196533203125, 0.00768280029296875, 0.03631591796875, 0.011199951171875, 0.033538818359375, 0.014984130859375, 0.00817108154296875, 0.01019287109375, 0.0322265625, 0.0014209747314453125, -0.006404876708984375, -0.0191497802734375, -0.0276947021484375, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35614>
      [
        [0.003330230712890625, 0.033843994140625, -0.034515380859375, -0.00818634033203125, 0.07989501953125, 0.1307373046875, 0.0264739990234375, 0.03955078125, -0.038543701171875, -0.10638427734375, 0.12744140625, -0.061431884765625, -0.03289794921875, -0.0115203857421875, 0.0157012939453125, ...],
        ...
      ]
    >
  },
  "decoder.blocks.3.cross_attention.query" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34747>
      [-0.173583984375, -0.09552001953125, 0.01041412353515625, 0.23095703125, -0.019287109375, 0.04876708984375, -0.08642578125, -0.022796630859375, -0.01058197021484375, -0.04205322265625, 0.061126708984375, 0.0386962890625, -0.1009521484375, 0.007568359375, -0.06695556640625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34744>
      [
        [0.0831298828125, -0.007015228271484375, -0.1328125, 0.023162841796875, -0.014404296875, 0.06719970703125, 0.02288818359375, -0.040283203125, -0.2080078125, -0.095947265625, 0.1014404296875, -0.0102081298828125, 0.10198974609375, 0.0205841064453125, ...],
        ...
      ]
    >
  },
  "decoder.blocks.8.ffn.intermediate" => %{
    "bias" => #Nx.Tensor<
      f32[4096]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34561>
      [-0.01200103759765625, -0.03509521484375, -0.10888671875, -0.182861328125, -0.148193359375, -0.12322998046875, -0.0986328125, -0.171142578125, -0.1265869140625, -0.0892333984375, -0.12188720703125, -0.12078857421875, -0.1480712890625, 0.0015668869018554688, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][4096]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34558>
      [
        [0.0301971435546875, 0.1329345703125, -0.013031005859375, 0.061798095703125, 0.0565185546875, -5.426406860351562e-4, -0.006877899169921875, 0.1663818359375, 0.03961181640625, 0.0232696533203125, -0.01439666748046875, 0.0185546875, 0.0260772705078125, ...],
        ...
      ]
    >
  },
  "decoder.blocks.9.self_attention.query" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35873>
      [-0.08746337890625, 0.18359375, 0.09002685546875, -0.26318359375, 0.049224853515625, -0.1466064453125, -0.04290771484375, 0.0931396484375, -0.099365234375, 0.07476806640625, -0.08831787109375, -0.2359619140625, -0.0199127197265625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35870>
      [
        [0.050262451171875, -0.0207672119140625, -0.01202392578125, 0.0160369873046875, -0.017669677734375, -0.007045745849609375, 0.053192138671875, 0.0948486328125, 0.052276611328125, -0.060638427734375, 0.0171051025390625, -0.0255584716796875, ...],
        ...
      ]
    >
  },
  "decoder.blocks.6.self_attention.key" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35995>
      [0.00794219970703125, -0.005176544189453125, 0.0013065338134765625, 0.00716400146484375, 0.009490966796875, -0.01049041748046875, -0.01113128662109375, 0.00463104248046875, 0.0299224853515625, -0.0117340087890625, 0.007640838623046875, -0.0029315948486328125, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35992>
      [
        [0.0733642578125, 0.02423095703125, 0.057525634765625, -0.057861328125, -0.083984375, -0.035858154296875, -0.150390625, 0.096923828125, 0.1024169921875, -3.7670135498046875e-4, -0.02166748046875, ...],
        ...
      ]
    >
  },
  "decoder.blocks.10.self_attention_norm" => %{
    "beta" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34713>
      [-0.0657958984375, 0.03900146484375, -0.059112548828125, -0.0465087890625, 0.03057861328125, -0.03662109375, -0.03912353515625, -0.09283447265625, -0.024749755859375, -0.05047607421875, -0.10968017578125, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34710>
      [0.7880859375, 0.70068359375, 0.7587890625, 0.7939453125, 0.7412109375, 0.73291015625, 0.77099609375, 0.77587890625, 0.75634765625, 0.7373046875, ...]
    >
  },
  "decoder.blocks.4.ffn.intermediate" => %{
    "bias" => #Nx.Tensor<
      f32[4096]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34793>
      [-0.126220703125, -0.06341552734375, -0.1456298828125, -0.1781005859375, -0.232421875, -0.03662109375, -0.00839996337890625, -0.14306640625, 0.037994384765625, -0.043060302734375, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][4096]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34790>
      [
        [0.001865386962890625, 0.021087646484375, 0.080810546875, 0.08978271484375, -0.01067352294921875, -0.023681640625, 0.01128387451171875, 0.01462554931640625, -0.0296630859375, ...],
        ...
      ]
    >
  },
  "sequence_classification_head.output" => %{
    "bias" => #Nx.Tensor<
      f32[3]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35827>
      [-6.622076034545898e-5, 1.3697147369384766e-4, -1.0222196578979492e-4]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][3]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35824>
      [
        [-0.04364013671875, 0.009490966796875, -0.016815185546875],
        [0.03765869140625, 0.0152130126953125, 0.0220794677734375],
        [0.0155487060546875, -0.0193023681640625, ...],
        ...
      ]
    >
  },
  "encoder.blocks.5.self_attention.query" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34599>
      [-0.01537322998046875, 0.168701171875, 0.02801513671875, -0.007678985595703125, 0.17431640625, -0.17578125, -0.00604248046875, -0.123779296875, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.34596>
      [
        [-0.08642578125, 0.095458984375, -0.0175323486328125, -0.111572265625, -0.046875, -0.0096282958984375, -0.07086181640625, ...],
        ...
      ]
    >
  },
  "decoder.blocks.0.self_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35647>
      [0.06768798828125, 0.318603515625, -0.079345703125, -0.0157470703125, 0.0225830078125, 0.04046630859375, -0.0428466796875, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35644>
      [
        [-0.0163726806640625, 0.030975341796875, 0.00830841064453125, 0.003387451171875, 0.01169586181640625, 0.0090484619140625, ...],
        ...
      ]
    >
  },
  "decoder.blocks.10.cross_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35557>
      [0.00345611572265625, -0.00786590576171875, -0.0679931640625, -0.01367950439453125, -2.9981136322021484e-5, -0.019500732421875, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35554>
      [
        [0.0018205642700195312, 0.03076171875, -0.01178741455078125, -0.0166778564453125, 0.028411865234375, ...],
        ...
      ]
    >
  },
  "decoder.blocks.2.cross_attention.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35549>
      [0.040740966796875, -0.1339111328125, 0.007709503173828125, 0.0167236328125, 0.06683349609375, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35546>
      [
        [-0.034332275390625, -0.0318603515625, -0.034942626953125, -0.05767822265625, ...],
        ...
      ]
    >
  },
  "encoder.blocks.9.output_norm" => %{
    "beta" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35919>
      [-0.0232391357421875, 0.08099365234375, 0.012359619140625, -0.0147705078125, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35916>
      [0.3759765625, 0.401123046875, 0.408447265625, ...]
    >
  },
  "decoder.blocks.4.self_attention.query" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36043>
      [-0.012481689453125, 0.13427734375, -0.05279541015625, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36040>
      [
        [0.060760498046875, -0.0135955810546875, ...],
        ...
      ]
    >
  },
  "decoder.blocks.8.output_norm" => %{
    "beta" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36471>
      [0.012725830078125, -0.0198822021484375, ...]
    >,
    "gamma" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36468>
      [0.4033203125, ...]
    >
  },
  "decoder.blocks.6.self_attention.value" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35367>
      [0.019866943359375, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[1024][1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.35364>
      [
        ...
      ]
    >
  },
  "encoder.blocks.3.ffn.output" => %{
    "bias" => #Nx.Tensor<
      f32[1024]
      EXLA.Backend<cuda:0, 0.3489919483.1697513501.36437>
      [...]
    >,
    ...
  },
  "decoder.blocks.3.ffn.output" => %{...},
  ...
}
```

```elixir
# this cell creates an %Nx.Serving{} struct which runs a zero-shot 
# classification task end-to-end.

labels = ["New booking", "Update booking", "Cancel booking", "Refund"]

zero_shot_serving =
  Bumblebee.Text.zero_shot_classification(
    model,
    tokenizer,
    labels
  )

# Nx.Serving is a high-level serving API which encapsulates 
# preprocessing, inference, and postprocessing.
```

<!-- livebook:{"output":true} -->

```
%Nx.Serving{
  module: Nx.Serving.Default,
  arg: #Function<3.24456354/2 in Bumblebee.Text.ZeroShotClassification.zero_shot_classification/4>,
  client_preprocessing: #Function<4.24456354/1 in Bumblebee.Text.ZeroShotClassification.zero_shot_classification/4>,
  client_postprocessing: #Function<5.24456354/2 in Bumblebee.Text.ZeroShotClassification.zero_shot_classification/4>,
  streaming: nil,
  batch_size: nil,
  distributed_postprocessing: &Function.identity/1,
  process_options: [batch_keys: [:default]],
  defn_options: [compiler: EXLA]
}
```

```elixir
input = "I need to book a new flight"
Nx.Serving.run(zero_shot_serving, input)
```

<!-- livebook:{"output":true} -->

```
%{
  predictions: [
    %{label: "New booking", score: 0.599165678024292},
    %{label: "Update booking", score: 0.3455483615398407},
    %{label: "Refund", score: 0.028283922001719475},
    %{label: "Cancel booking", score: 0.027001969516277313}
  ]
}
```

```elixir
inputs = [
  "I want to change my existing flight",
  "I want to cancel my current flight",
  "I demand my money back"
]

Nx.Serving.run(zero_shot_serving, inputs)
```

<!-- livebook:{"output":true} -->

```
[
  %{
    predictions: [
      %{label: "New booking", score: 0.43927034735679626},
      %{label: "Update booking", score: 0.42686450481414795},
      %{label: "Cancel booking", score: 0.10792665928602219},
      %{label: "Refund", score: 0.025938473641872406}
    ]
  },
  %{
    predictions: [
      %{label: "Cancel booking", score: 0.5605530142784119},
      %{label: "Refund", score: 0.3020729720592499},
      %{label: "Update booking", score: 0.09756790101528168},
      %{label: "New booking", score: 0.03980613872408867}
    ]
  },
  %{
    predictions: [
      %{label: "Refund", score: 0.9138062596321106},
      %{label: "Cancel booking", score: 0.047362904995679855},
      %{label: "Update booking", score: 0.024916373193264008},
      %{label: "New booking", score: 0.013914480805397034}
    ]
  }
]
```

**Making Conversation**

```elixir
repo = {:hf, "openai-community/gpt2"}
{:ok, model_info} = Bumblebee.load_model(repo)
{:ok, tokenizer} = Bumblebee.load_tokenizer(repo)
{:ok, generation_config} = Bumblebee.load_generation_config(repo)

generation_config =
  Bumblebee.configure(generation_config,
    max_new_tokens: 256,
    strategy: %{type: :multinomial_sampling, top_p: 0.6}
  )

serving =
  Bumblebee.Text.generation(
    model_info,
    tokenizer,
    generation_config,
    compile: [batch_size: 1, sequence_length: 1028],
    stream: true,
    defn_options: [compiler: EXLA]
  )
```

<!-- livebook:{"output":true} -->

```
|=============================================================| 100% (548.11 MB)
|===============================================================| 100% (1.35 MB)
```

<!-- livebook:{"output":true} -->

```
%Nx.Serving{
  module: Nx.Serving.Default,
  arg: #Function<0.77086443/2 in Bumblebee.Text.TextGeneration.generation/4>,
  client_preprocessing: #Function<1.77086443/1 in Bumblebee.Text.TextGeneration.generation/4>,
  client_postprocessing: #Function<2.77086443/2 in Bumblebee.Text.TextGeneration.maybe_stream/4>,
  streaming: %{hooks: [:token]},
  batch_size: 1,
  distributed_postprocessing: &Function.identity/1,
  process_options: [batch_keys: [sequence_length: 1028]],
  defn_options: [compiler: EXLA]
}
```

```elixir
Kino.start_child({Nx.Serving, name: Gemma, serving: serving})
```

<!-- livebook:{"output":true} -->

```

22:42:02.449 [info] ptxas warning : Registers are spilled to local memory in function 'sort_3', 632 bytes spill stores, 616 bytes spill loads
ptxas warning : Registers are spilled to local memory in function 'sort_2707', 632 bytes spill stores, 616 bytes spill loads


```

<!-- livebook:{"output":true} -->

```
{:ok, #PID<0.383.0>}
```

```elixir
user_input = Kino.Input.textarea("User prompt", default: "Who are you?")
```

```elixir
user = Kino.Input.read(user_input)

prompt = """
#{user}
"""

Nx.Serving.batched_run(Gemma, prompt)
|> Enum.each(&IO.write/1)
```

<!-- livebook:{"output":true} -->

```

know how to solve puzzles. I'm very motivated and do it

slowly and I do it with a lot of practice.

I have been here for 4 years and I've seen it

never fail to impress.

I'm also a real teacher, teacher,

I love teaching and it's really important to me

to be able to give back to the community and to the

machines and do that in a way that's very human.

I'm a very happy person, and I am a big

guy and I love to do things.

So I am here for a reason.

I'm here for the right reasons.

I want to do something different.

I want to be a teacher.

I want to be a teacher for the whole community.

I want to be a teacher for the community and the

machines and for the people that care about it.

I want to be a teacher for the community.

I want to be a teacher for the community and the

machines and for the people that care about it.

I want to be a teacher for the community and the
```

<!-- livebook:{"output":true} -->

```
:ok
```

Bumblebee uses a greedy text generation strategy to generate tokens
from a sequence. The greedy strategy generates one token of the sequence at
a time by predicting the most probable next token.

Bumblebee also supports more complex generation strategies out of the box.

Generation strategies and hyperparameters often have a significant impact
on the quality of generations.
