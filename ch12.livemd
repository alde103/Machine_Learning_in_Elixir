<!-- livebook:{"persist_outputs":true} -->

# Chapter 12. Learn without Supervision

```elixir
Mix.install(
  [
    {:axon, "~> 0.6"},
    {:nx, "~> 0.7"},
    {:kino, "~> 0.8"},
    {:scidata, "~> 0.1"},
    {:exla, ">= 0.0.0"}
  ],
  config: [nx: [default_backend: {EXLA.Backend, client: :cuda}]]
  #config: []
)

# export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}
# export XLA_TARGET=cuda120 
#Nx.global_default_backend(EXLA.Backend)
Nx.Defn.global_default_options(compiler: EXLA)
```

## Introduction

The reality is that a majority of data you encounter is unlabeled. Equally problematic is that labeling data is an expensive, tedious, and time-consuming task.

Unsupervised learning is learning to capture relationships in data without an explicit target (without labels).

## Compressing Data with Autoencoders

In a compression algorithm, your goal is to reduce the size of the original data—typically by
taking advantage of patterns and structures of the input data. In an unsupervised learning problem, your goal is to capture or model the patterns and structures of the input data.

A neural network learns to compress data, and then you
can train an additional neural network to decompress the compressed form.

An autoencoder is a neural network that consists of an encoder and a decoder.

The encoder learns a latent representation of input data. A latent representation is a compressed representation of input data in which similar items are close together in space.

The decoder learns to reconstruct input data from the latent representation. The goal of an autoencoder is to map an input to a latent representation and back with minimal information loss. The output of the decoder should resemble the input as much as possible.

```elixir
{{data, type, shape}, _} = Scidata.MNIST.download()

batch_size = 64

train_data =
  data
  |> Nx.from_binary(type)
  |> Nx.reshape({:auto, 28, 28, 1})
  |> Nx.divide(255)
  |> Nx.to_batched(batch_size)
```

<!-- livebook:{"output":true} -->

```

21:00:05.912 [info] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355

21:00:05.912 [info] XLA service 0x7f6a000215e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:

21:00:05.912 [info]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5

21:00:05.912 [info] Using BFC allocator.

21:00:05.912 [info] XLA backend allocating 5420482560 bytes on device 0 for BFCAllocator.

21:00:06.165 [info] Loaded cuDNN version 8907

21:00:06.214 [info] Using nvlink for parallel linking

```

<!-- livebook:{"output":true} -->

```
#Stream<[enum: 0..937, funs: [#Function<48.53678557/1 in Stream.map/2>]]>
```

```elixir
defmodule Autoencoder do
  def encoder(input) do
    input
    |> Axon.flatten()
    |> Axon.dense(256, activation: :relu, name: "encoder_dense_0")
    |> Axon.dense(128, activation: :relu, name: "encoder_dense_1")
  end

  def decoder(input) do
    input
    |> Axon.dense(256, activation: :relu, name: "decoder_dense_0")
    |> Axon.dense(784, activation: :sigmoid, name: "decoder_dense_1")
    |> Axon.reshape({:batch, 28, 28, 1})
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, Autoencoder, <<70, 79, 82, 49, 0, 0, 8, ...>>, {:decoder, 1}}
```

```elixir
model =
  Axon.input("image")
  |> Autoencoder.encoder()
  |> Autoencoder.decoder()
```

<!-- livebook:{"output":true} -->

```
#Axon<
  inputs: %{"image" => nil}
  outputs: "reshape_0"
  nodes: 11
>
```

```elixir
test_batch = Enum.at(train_data, 0)
test_image = test_batch[0] |> Nx.new_axis(0)

visualize_test_image = fn
  %Axon.Loop.State{step_state: step_state} = state ->
    out_image =
      Axon.predict(
        model,
        step_state[:model_state],
        test_image,
        compiler: EXLA
      )

    out_image =
      out_image
      |> Nx.multiply(255)
      |> Nx.as_type(:u8)
      |> Nx.reshape({28, 28, 1})

    Kino.Image.new(out_image) |> Kino.render()
    {:continue, state}
end
```

<!-- livebook:{"output":true} -->

```
#Function<42.105768164/1 in :erl_eval.expr/6>
```

```elixir
trained_model_state =
  model
  |> Axon.Loop.trainer(:mean_squared_error, Axon.Optimizers.adam(1.0e-3))
  |> Axon.Loop.handle_event(:epoch_completed, visualize_test_image)
  |> Axon.Loop.run(
    Stream.zip(train_data, train_data),
    %{},
    epochs: 5,
    compiler: EXLA
  )
```

<!-- livebook:{"output":true} -->

```
warning: Axon.Optimizers.adam/1 is deprecated. Use Polaris.Optimizers.adam/1 instead
└─ /home/alde/Documents/MyDevelopment/Machine_Learning_in_Elixir/ch12.livemd#cell:a3qiuihog2hwqlw7:3


22:45:16.751 [debug] Forwarding options: [compiler: EXLA] to JIT compiler
Epoch: 0, Batch: 900, loss: 0.0243214
```

<!-- livebook:{"output":true} -->

```
Epoch: 1, Batch: 912, loss: 0.0158038
```

<!-- livebook:{"output":true} -->

```
Epoch: 2, Batch: 924, loss: 0.0123496
```

<!-- livebook:{"output":true} -->

```
Epoch: 3, Batch: 936, loss: 0.0103900
```

<!-- livebook:{"output":true} -->

```
Epoch: 4, Batch: 898, loss: 0.0091604
```

<!-- livebook:{"output":true} -->

```
%{
  "decoder_dense_0" => %{
    "bias" => #Nx.Tensor<
      f32[256]
      EXLA.Backend<cuda:0, 0.3428917133.3471966240.230339>
      [-0.024319563060998917, -0.03374124690890312, -0.016717825084924698, 0.20613473653793335, 0.26516419649124146, 0.044232748448848724, 0.0857461467385292, -0.012179962359368801, -0.037334613502025604, 0.004324085079133511, -0.07982579618692398, -0.11133469641208649, 0.09377171844244003, 0.03962923213839531, 0.042364731431007385, 0.060100357979536057, 0.24876253306865692, -0.008186716586351395, -0.1386401206254959, 0.07425974309444427, 0.03563845902681351, 0.26992297172546387, 0.10051167756319046, 0.03290257602930069, 0.1498967707157135, 0.23329195380210876, 0.0025002947077155113, 0.20460094511508942, 0.03520585596561432, 0.06461299955844879, 0.17768751084804535, 0.09494055062532425, 0.08655203878879547, 0.08160529285669327, 0.057952508330345154, 0.08393292874097824, -0.009104117751121521, -0.033990923315286636, -0.1701013147830963, 0.045080527663230896, 0.014088070020079613, 0.05248705670237541, 0.09189663827419281, 0.23571713268756866, 0.05827738344669342, -0.034953705966472626, 0.08573732525110245, 0.18495285511016846, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[128][256]
      EXLA.Backend<cuda:0, 0.3428917133.3471966240.230340>
      [
        [0.036289282143116, -0.2135372757911682, 0.07855630666017532, 0.14507223665714264, -0.005494407843798399, 0.02439933456480503, -0.10730762034654617, -0.036758773028850555, 0.06838040053844452, 0.04490184783935547, -0.09203695505857468, -0.08849064260721207, 0.144709512591362, -0.08479256927967072, -0.08964014053344727, -0.1022753119468689, 0.10379327088594437, -0.11440812796354294, 0.2056046724319458, -0.03955991566181183, 0.005439110565930605, -0.09337763488292694, -0.009114908054471016, -0.03031492792069912, -0.04412383586168289, 0.0961625874042511, 0.09390757977962494, 0.1671614646911621, -0.041649576276540756, -0.057799335569143295, 0.011180946603417397, -0.15465663373470306, 0.028233850374817848, 0.021884417161345482, 0.08190984278917313, -0.10658582299947739, 0.012095038779079914, 0.00865098088979721, 0.09590816497802734, -0.12158184498548508, -0.006460580974817276, -0.1260594129562378, -0.113841213285923, -0.0433875247836113, -0.03082657977938652, 0.07832618802785873, -0.2148934155702591, ...],
        ...
      ]
    >
  },
  "decoder_dense_1" => %{
    "bias" => #Nx.Tensor<
      f32[784]
      EXLA.Backend<cuda:0, 0.3428917133.3471966240.230341>
      [-0.01890827715396881, -0.022221922874450684, -0.01796412095427513, -0.017382705584168434, -0.01795188896358013, -0.019038164988160133, -0.01985081471502781, -0.01671929471194744, -0.018723471090197563, -0.01885196752846241, -0.018992308527231216, -0.01831326261162758, -0.01709422655403614, -0.017499899491667747, -0.018796110525727272, -0.015335873700678349, -0.016313614323735237, -0.020302463322877884, -0.020274663344025612, -0.01651875674724579, -0.01874568499624729, -0.023971108719706535, -0.021038953214883804, -0.018940318375825882, -0.01694750227034092, -0.016278278082609177, -0.02010621316730976, -0.01965896598994732, -0.019567320123314857, -0.01715899258852005, -0.01883556693792343, -0.017868967726826668, -0.017669646069407463, -0.019557034596800804, -0.019245490431785583, -0.018234388902783394, -0.018702276051044464, -0.020627278834581375, -0.019365452229976654, -0.019128426909446716, -0.018891552463173866, -0.019146185368299484, -0.017600052058696747, -0.018922096118330956, -0.01679682359099388, -0.01848248392343521, -0.01793292909860611, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[256][784]
      EXLA.Backend<cuda:0, 0.3428917133.3471966240.230342>
      [
        [0.01906551979482174, -0.02295497991144657, -0.029860589653253555, -0.07156840711832047, -0.05390588566660881, -0.07356256991624832, 0.013172361068427563, -0.0729248896241188, 0.043269138783216476, -0.01576106809079647, -0.0335020013153553, 0.02729194052517414, 0.035664837807416916, -0.009749239310622215, 0.0099441884085536, -0.04757070168852806, -0.07439646869897842, -0.08996418863534927, -0.08803759515285492, -0.06495393067598343, 0.020452234894037247, -0.09426551312208176, 0.02612890861928463, -0.08544730395078659, 0.05906157195568085, -0.05082722753286362, 0.03746887296438217, -0.07631582021713257, 0.040888912975788116, -0.02488127537071705, -0.03238377347588539, -0.0066023943945765495, -0.09095389395952225, 0.010581274516880512, -0.03874997794628143, -0.04148449748754501, -0.08805596083402634, 5.575495306402445e-4, -0.08704648166894913, -0.011238637380301952, -0.019110072404146194, 0.03316256031394005, 0.03436431661248207, -0.027826089411973953, 0.024035047739744186, -0.07673566043376923, ...],
        ...
      ]
    >
  },
  "encoder_dense_0" => %{
    "bias" => #Nx.Tensor<
      f32[256]
      EXLA.Backend<cuda:0, 0.3428917133.3471966240.230343>
      [-0.043304648250341415, 0.18399764597415924, 0.04203381389379501, -0.23011547327041626, -0.1629650741815567, 0.217673197388649, -0.0904146283864975, -0.1073060855269432, 0.4499191343784332, -0.016620555892586708, -0.013919045217335224, -0.0183483324944973, 0.013764440082013607, 0.3377233147621155, -0.05179639160633087, -0.015441849827766418, 0.15188662707805634, 0.34805935621261597, 0.44170573353767395, 0.39827418327331543, 0.10207138955593109, 0.29315048456192017, 0.026342473924160004, 0.39629653096199036, 0.12565544247627258, -0.02435440756380558, 0.25359106063842773, 0.3309515714645386, 0.008823877200484276, -0.016512786969542503, -0.23005779087543488, 0.22069525718688965, 0.04882504418492317, 0.42909932136535645, -0.023875132203102112, 0.07319298386573792, 0.2171703279018402, 0.31034576892852783, 0.17945905029773712, -0.016712933778762817, -0.2314833402633667, 0.28654688596725464, -0.09044083207845688, 0.4354754090309143, -0.08637525141239166, 0.3914473056793213, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[784][256]
      EXLA.Backend<cuda:0, 0.3428917133.3471966240.230344>
      [
        [-0.0528387613594532, -0.025719180703163147, -0.026644594967365265, -0.051880404353141785, -0.02537517622113228, -0.074128158390522, 0.009387113153934479, -0.03258788585662842, 0.01668928563594818, 0.06479679048061371, 0.07447077333927155, -0.05711597204208374, 0.030320636928081512, -0.06568504124879837, -0.05649399012327194, -0.010931521654129028, -0.05200745910406113, 0.06635327637195587, 0.06338390707969666, 0.022689059376716614, -0.014755766838788986, -0.05040675029158592, -0.014982875436544418, -0.05151403695344925, 0.017536848783493042, -0.07139655202627182, -0.008578360080718994, 0.05103267729282379, 0.0523449182510376, -0.05528717860579491, 0.06982368230819702, -0.0017823576927185059, -0.0037224367260932922, -0.0015469565987586975, 0.07054616510868073, -0.025325339287519455, 0.040206313133239746, 0.05921439826488495, 0.0066007450222969055, -0.0026065632700920105, -0.037024691700935364, 0.025455981492996216, 0.025124602019786835, -0.04962915927171707, -0.04361710697412491, ...],
        ...
      ]
    >
  },
  "encoder_dense_1" => %{
    "bias" => #Nx.Tensor<
      f32[128]
      EXLA.Backend<cuda:0, 0.3428917133.3471966240.230345>
      [-0.25381365418434143, -0.09696804732084274, 0.002558395266532898, 0.2607980966567993, -0.1399974226951599, 0.3650723397731781, 0.15049226582050323, 0.391552209854126, 0.33854782581329346, 0.16475211083889008, 0.18273599445819855, -0.0920567736029625, -0.012684471905231476, 0.1389341503381729, 0.22568641602993011, -0.11369340866804123, -0.12058866769075394, -0.007696834858506918, 0.257377028465271, 0.2930028736591339, 0.19295921921730042, -0.08680175244808197, 0.09907509386539459, 0.11535894870758057, 0.16169796884059906, 0.11744023859500885, -0.029378218576312065, 0.10478008538484573, 0.12443793565034866, 0.02954523265361786, -0.045433059334754944, 0.29974696040153503, -0.03539813682436943, 0.1295410543680191, -0.009887678548693657, -0.20914055407047272, 0.112053282558918, -0.005428957752883434, 0.04919718578457832, 0.3200157582759857, 0.04826745018362999, -0.19935789704322815, 0.1015954315662384, -0.01453453116118908, -0.011737392283976078, ...]
    >,
    "kernel" => #Nx.Tensor<
      f32[256][128]
      EXLA.Backend<cuda:0, 0.3428917133.3471966240.230346>
      [
        [0.09061522036790848, -0.029385391622781754, -0.05518260598182678, 0.06527890264987946, -0.027372321113944054, -0.11267683655023575, 0.11759626865386963, -0.07666678726673126, -0.06786229461431503, 0.055323660373687744, 0.10072305053472519, -0.0053148395381867886, -0.1320914626121521, 0.03561873361468315, -0.01970522478222847, -0.01765655353665352, -0.14466367661952972, 0.07918056100606918, -0.12090840935707092, -0.0616278350353241, -0.1108192428946495, 0.04582803696393967, 0.03960726782679558, 0.029154863208532333, -0.0930435061454773, -0.01873568445444107, -0.010780547745525837, -0.12350839376449585, 0.0869125947356224, 0.017338985577225685, 0.05443299561738968, 0.05515207722783089, -0.11704619973897934, -0.059532057493925095, 0.10277421027421951, 0.12634873390197754, -0.012780209071934223, 0.08235663175582886, 0.006001143716275692, 0.09322859346866608, 0.07398451864719391, -0.09769970178604126, -0.06995069235563278, -0.05189216136932373, ...],
        ...
      ]
    >
  }
}
```

```elixir
# A deep generative model is a deep learning model designed to generate
# data from some distribution.

decoder_only =
  Axon.input("noise")
  |> Autoencoder.decoder()

key = Nx.Random.key(42)
{noise, _key} = Nx.Random.normal(key, shape: {1, 128})
out_image = Axon.predict(decoder_only, trained_model_state, noise)
upsampled = Axon.Layers.resize(out_image, size: {512, 512})

out_image =
  upsampled
  |> Nx.reshape({512, 512, 1})
  |> Nx.multiply(255)
  |> Nx.as_type(:u8)

Kino.Image.new(out_image)
```

The structure of your encoded representations is at the mercy of a neural network and gradient descent. You can’t just pass random uniform or normal noise to your decoder and expect
coherent output, because your decoder only knows how to handle latent
representations produced by the encoder.

```elixir

```
